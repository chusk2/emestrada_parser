{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selectividad Exams Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt update\n",
    "# !sudo apt install tesseract-ocr tesseract-ocr-spa poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdf2image\n",
    "# !pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory, pattern):\n",
    "    path = Path(directory)\n",
    "    return path.rglob(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = sorted( [i for i in find_files(directory='./pdf_files',\n",
    "                                            pattern='*.pdf') \n",
    "              if i.name.startswith('2')\n",
    "              ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse pdf pages into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pages_ocr(file_path):\n",
    "    images = convert_from_path(file_path)[1:]\n",
    "    # parse each page\n",
    "    pages = []\n",
    "    for i, page in enumerate(images):\n",
    "        pages.append(pytesseract.image_to_string(page, lang='spa'))\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract statement text from page text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statement(page):\n",
    "    # split the content into lines\n",
    "    text = page.split('\\n')\n",
    "    # list to store the processed lines\n",
    "    final_text = []\n",
    "    # start from the 4th line\n",
    "    for line in text[4:]:\n",
    "        # stop at RESOLUCION\n",
    "        if line.startswith('RESOLUCIÓN'):\n",
    "            break\n",
    "        # add the line to final_text\n",
    "        else:\n",
    "            if not line == '':\n",
    "                final_text.append(line.strip())\n",
    "    # join the list into a single string\n",
    "    final_text = '\\n'.join(final_text)\n",
    "\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract exam datails from statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exam_details(statement):\n",
    "    # get last line with exam details\n",
    "    lines = [i for i in statement.split('\\n') if i != '']\n",
    "    exam_details = lines[-1]\n",
    "    # split the words by ' '\n",
    "    exam_details = exam_details.split(' ')\n",
    "    # strip whitespaces\n",
    "    exam_details = [i.replace('.', '').strip() for i in exam_details]\n",
    "\n",
    "    # exam dictionary\n",
    "    exam_dict = {}\n",
    "\n",
    "    # fill dictionary with values\n",
    "    exam_dict['subject'] = exam_details[0].title()\n",
    "    exam_dict['year'] = int(exam_details[1])\n",
    "\n",
    "    # parse the exam string\n",
    "    if exam_details[2].startswith('RESERVA'):\n",
    "        exam_dict['exam'] = ' '.join(exam_details[2:4]).title()\n",
    "        exam_index_start = 4\n",
    "    else:\n",
    "        exam_dict['exam'] = exam_details[2].title()\n",
    "        exam_index_start = 3\n",
    "    \n",
    "    exam_dict['exercise'] = ' '.join(exam_details[exam_index_start:]).title()\n",
    "    \n",
    "    return exam_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises_dict = {}\n",
    "for file in file_paths:\n",
    "    topic = file.stem.split(' - ')[-1]   \n",
    "    \n",
    "    # lists to store the values\n",
    "    subjects = []\n",
    "    years = []\n",
    "    exams = []\n",
    "    exercises = []\n",
    "    statements = []\n",
    "    pages = parse_pages_ocr(file)\n",
    "\n",
    "    try:\n",
    "        for index, page in enumerate(pages):\n",
    "            statement = extract_statement(page)\n",
    "            details = extract_exam_details(statement)\n",
    "            subjects.append(details['subject'])\n",
    "            years.append(details['year'])\n",
    "            exams.append(details['exam'])\n",
    "            exercises.append(details['exercise'])\n",
    "            statements.append(statement)\n",
    "        \n",
    "        print(f'Success parsing file: {file.stem}')\n",
    "    except:\n",
    "        # safe errors to log file\n",
    "        with open('errors.log', 'a') as f:\n",
    "            string = f'Error in {file.name}: page {index+2}\\n'\n",
    "            f.write(string)\n",
    "            print(string)\n",
    "        \n",
    "        continue\n",
    "\n",
    "    # generate the key and content for the exercises dictionary\n",
    "    key = details['subject'] + ' ' + str(details['year']) + ' ' + topic\n",
    "    exercises_dict[key] = {\n",
    "        'subject' : subjects,\n",
    "        'year' : years,\n",
    "        'topic' : [topic] * len(subjects),\n",
    "        'exam' : exams,\n",
    "        'exercise' : exercises,\n",
    "        'statement' : statements\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the parsed content into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to store the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary keys from the first processed file\n",
    "first_processed_file = list(exercises_dict.keys())[0]\n",
    "# create the dict from keys\n",
    "content = dict.fromkeys(exercises_dict[first_processed_file].keys())\n",
    "# fill the dict with empty lists\n",
    "for key in content.keys():\n",
    "    content[key] = []\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract values from the dictionary for each subject/year/topic file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each year contains a dictionary with keys containing lists of values\n",
    "for year, dict_ in exercises_dict.items():\n",
    "    # loop through the dictionary\n",
    "    for key, value in dict_.items():\n",
    "        content[key].extend(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct wrong subjects\n",
    "df.subject = df.subject.apply(lambda x: 'Química' if x.endswith('mica') else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export `exercises` to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in df['subject'].unique():\n",
    "    df[df['subject'] == subject].to_csv(f'exercises_{subject}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
