{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selectividad Exams Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory, pattern):\n",
    "    path = Path(directory)\n",
    "    return path.rglob(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = sorted( [i for i in find_files(directory='./pdf_files', pattern='.pdf') \n",
    "              if i.name.startswith('2')\n",
    "              ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(file_path):\n",
    "    \"\"\"\n",
    "    Extract relevant information from a single PDF file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to the PDF file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing the extracted information. The keys are:\n",
    "            - subject\n",
    "            - topic\n",
    "            - year\n",
    "            - exam_name\n",
    "            - exercise\n",
    "            - statement\n",
    "            - page\n",
    "            - exam_details\n",
    "    \"\"\"\n",
    "\n",
    "    # define keys for the content dictionary\n",
    "    content = {\n",
    "        'subject': [],\n",
    "        'topic' : [],\n",
    "        'year': [],\n",
    "        'page': [],\n",
    "        'exam_details': [],\n",
    "        'exam_name': [],\n",
    "        'exercise': [],\n",
    "        'statement': [],\n",
    "    }\n",
    "\n",
    "    # open the pdf file to be parsed\n",
    "    doc = fitz.open(file_path)\n",
    "\n",
    "    # process individual pages\n",
    "    for page in doc[1:]:\n",
    "        \n",
    "        # get content of the page\n",
    "        text = page.get_text(\"text\")\n",
    "        \n",
    "        ### clean the content of page\n",
    "        # replacements\n",
    "        replacements = {'www.emestrada.org' : '',\n",
    "                        'R  E  S  O  L  U  C  I  Ó  N': 'Resolucion',\n",
    "                        '\\n \\n \\n' : ''}\n",
    "\n",
    "        for subs, rep in replacements.items():\n",
    "            text =  text.replace(subs, rep)\n",
    "        \n",
    "        # remove whitespaces and create list of rows\n",
    "        text = text.strip().replace('  ', ' ').split('\\n')\n",
    "        ###\n",
    "\n",
    "        # extract exam details\n",
    "        exam_details = text[-1]\n",
    "\n",
    "        ### parse the text of the page\n",
    "        # extract text of the page\n",
    "        text = text[:-1]\n",
    "\n",
    "        # extract only exercise statement\n",
    "        times_a_appeared = 0\n",
    "        for index, row in enumerate(text):\n",
    "            if 'a)' in row:\n",
    "                times_a_appeared += 1\n",
    "                # it's the second occurrence of a)\n",
    "                if times_a_appeared == 2:\n",
    "                    text = text[index:]\n",
    "                    # remove any text before \"a)\"\n",
    "                    text[0] = 'a)' + text[0].split('a)')[1]\n",
    "                    break\n",
    "        \n",
    "        # remove relative masses part\n",
    "        for index, row in enumerate(text):\n",
    "            if 'dato' in row.lower() :\n",
    "                if not row.lower().startswith('dato'):\n",
    "                    dato_index = row.lower().find('dato')\n",
    "                    text[index] = row[:dato_index]\n",
    "                    text = text[:index+1]\n",
    "                # row starts with \"Dato:\"\n",
    "                else:\n",
    "                    text = text[:index]\n",
    "                break\n",
    "        \n",
    "        # remove the lines starting with just a number\n",
    "        text = [i for i in text if len(i) > 1]\n",
    "        \n",
    "        # join the lines of the statement\n",
    "        joined_text = ''\n",
    "        for row in text:\n",
    "\n",
    "            if ' b) ' in row:\n",
    "                row = row.split('b)')\n",
    "                joined_text += row[0] + '\\n' + 'b) ' + row[1]\n",
    "            elif row.startswith('b'):\n",
    "                joined_text += '\\n' + row\n",
    "            else:\n",
    "                joined_text += row\n",
    "\n",
    "        # finally remove double whitespases\n",
    "        statement = joined_text.replace('  ', ' ')\n",
    "        ### end of parsing text\n",
    "\n",
    "        ### extract: year, exam name and exercise\n",
    "\n",
    "        # create empty values for exam details\n",
    "        # that will be filled with proper values\n",
    "        # if the exam details can be parsed\n",
    "        subject, year, exam_name, exercise = ['-'] * 4\n",
    "\n",
    "        # parse the exam details\n",
    "        try:\n",
    "            exam = exam_details.split(' ')\n",
    "            # extract subject\n",
    "            subject = exam[0].replace('.', '').title()\n",
    "            # extract year\n",
    "            year = exam[1].replace('.', '')\n",
    "            # get exam\n",
    "            if exam[2] == 'RESERVA':\n",
    "                exam_name = exam[2].title() +  ' ' + ' '.join(exam[3]).replace('.', '').strip()\n",
    "            else:\n",
    "                exam_name = exam[2].title().replace('.', '').strip()\n",
    "            # get exercise\n",
    "            if exam[2] == 'RESERVA':\n",
    "                exercise = ' '.join(exam[4:]).title().replace('.', '').strip()\n",
    "            else:\n",
    "                exercise = ' '.join(exam[3:]).title().replace('.', '').strip()\n",
    "        \n",
    "        # if there were errors, generate error message and log it\n",
    "        except:\n",
    "            error_message = f'Failed parsing exercise details: {file_path.name} - page {page.number + 1}'\n",
    "            print(error_message)\n",
    "            # add to error log\n",
    "            with open('errors.txt', 'a') as f:\n",
    "                f.write(error_message + '\\n')      \n",
    "        \n",
    "        ### end of parsing exam details\n",
    "\n",
    "        # update the content dict\n",
    "        content['subject'].append(subject)\n",
    "        content['topic'].append(file_path.stem.split(' - ')[-1])\n",
    "        content['year'].append(year)\n",
    "        content['exam_name'].append(exam_name)\n",
    "        content['exercise'].append(exercise)\n",
    "        content['statement'].append(statement)\n",
    "        content['page'].append(page.number + 1)\n",
    "        content['exam_details'].append(exam_details)\n",
    "        \n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check exam string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exam_string(exam_details):\n",
    "    page_dict = {}\n",
    "    exam = exam_details.split(' ')\n",
    "\n",
    "    # extract subject\n",
    "    page_dict['subject'] = (exam[0]\n",
    "                            .replace('.', '')\n",
    "                            .title()\n",
    "    )\n",
    "    page_dict['year'] = exam[1].replace('.', '')\n",
    "    # get exam\n",
    "    if exam[2] == 'RESERVA':\n",
    "        page_dict['exam'] = exam[2].title() +  ' ' + ' '.join(exam[3])\n",
    "    else:\n",
    "        page_dict['exam'] = exam[2].title()\n",
    "    # get exercise\n",
    "    if exam[2] == 'RESERVA':\n",
    "        page_dict['exercise'] = ' '.join(exam[4:]).title()\n",
    "    else:\n",
    "        page_dict['exercise'] = ' '.join(exam[3:]).title()\n",
    "\n",
    "    return page_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'Quimica',\n",
       " 'year': '2005',\n",
       " 'exam': 'Reserva 1 .',\n",
       " 'exercise': 'Ejercicio 5. Opción A'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_exam_string('QUIMICA. 2005. RESERVA 1. EJERCICIO 5. OPCIÓN A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises = {}\n",
    "\n",
    "for file in file_paths:\n",
    "    exam = file.stem\n",
    "    exercises[exam] = extract_info(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to a JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exercises.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(exercises, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m first_exercise \u001b[38;5;241m=\u001b[39m exercises[ \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mexercises\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m ]\n\u001b[1;32m      2\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(first_exercise\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m columns\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "first_exercise = exercises[ list( exercises.keys() )[0] ]\n",
    "columns = list(first_exercise.keys())\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary\n",
    "Dictionary keys: subject, topic, year, exam_name, exercise, statement, page, exam_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "content_dict = dict.fromkeys(columns)\n",
    "for key in content_dict.keys():\n",
    "    content_dict[key] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exercise, content in exercises.items():\n",
    "    for key, value in content.items():\n",
    "        content_dict[key].extend(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises_df = pd.DataFrame(content_dict)\n",
    "# replace '-' with NaN\n",
    "exercises_df.replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1840 entries, 0 to 1839\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   subject       1840 non-null   object\n",
      " 1   topic         1840 non-null   object\n",
      " 2   year          1812 non-null   object\n",
      " 3   page          1840 non-null   int64 \n",
      " 4   exam_details  1840 non-null   object\n",
      " 5   exam_name     1809 non-null   object\n",
      " 6   exercise      1809 non-null   object\n",
      " 7   statement     1840 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 115.1+ KB\n"
     ]
    }
   ],
   "source": [
    "exercises_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export `exercises` to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in exercises_df['subject'].unique():\n",
    "    exercises_df[exercises_df['subject'] == subject].to_csv(f'exercises_{subject}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
